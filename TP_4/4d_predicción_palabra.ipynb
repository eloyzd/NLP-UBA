{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto utilizando la layer Embedding de Keras. Se utilizará esos embeddings junto con layers LSTM para predeccir la próxima posible palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkdPfrQJZdB5",
        "outputId": "55ce58da-14ac-4d17-af1a-cf5b13a6c166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-03 12:38:43--  http://songs_dataset.zip/\n",
            "Resolving songs_dataset.zip (songs_dataset.zip)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘songs_dataset.zip’\n",
            "--2022-08-03 12:38:43--  https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/datasets/songs_dataset.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip [following]\n",
            "--2022-08-03 12:38:43--  https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2075036 (2.0M) [application/zip]\n",
            "Saving to: ‘songs_dataset.zip’\n",
            "\n",
            "songs_dataset.zip   100%[===================>]   1.98M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-08-03 12:38:44 (48.2 MB/s) - ‘songs_dataset.zip’ saved [2075036/2075036]\n",
            "\n",
            "FINISHED --2022-08-03 12:38:44--\n",
            "Total wall clock time: 0.7s\n",
            "Downloaded: 1 files, 2.0M in 0.04s (48.2 MB/s)\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import platform\n",
        "if os.access('./songs_dataset', os.F_OK) is False:\n",
        "    if os.access('songs_dataset.zip', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip -o songs_dataset.zip\n",
        "        else:\n",
        "            !wget songs_dataset.zip https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/datasets/songs_dataset.zip\n",
        "    !unzip -q songs_dataset.zip   \n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j-3nQ4lZjfb",
        "outputId": "eb8a2af6-5ea7-4c42-f5b6-06c741951f54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['radiohead.txt',\n",
              " 'Lil_Wayne.txt',\n",
              " 'kanye.txt',\n",
              " 'janisjoplin.txt',\n",
              " 'amy-winehouse.txt',\n",
              " 'prince.txt',\n",
              " 'nirvana.txt',\n",
              " 'ludacris.txt',\n",
              " 'blink-182.txt',\n",
              " 'rihanna.txt',\n",
              " 'bieber.txt',\n",
              " 'leonard-cohen.txt',\n",
              " 'lorde.txt',\n",
              " 'r-kelly.txt',\n",
              " 'patti-smith.txt',\n",
              " 'dr-seuss.txt',\n",
              " 'jimi-hendrix.txt',\n",
              " 'britney-spears.txt',\n",
              " 'adele.txt',\n",
              " 'nicki-minaj.txt',\n",
              " 'lil-wayne.txt',\n",
              " 'dolly-parton.txt',\n",
              " 'bruno-mars.txt',\n",
              " 'bob-dylan.txt',\n",
              " 'al-green.txt',\n",
              " 'joni-mitchell.txt',\n",
              " 'michael-jackson.txt',\n",
              " 'notorious-big.txt',\n",
              " 'eminem.txt',\n",
              " 'alicia-keys.txt',\n",
              " 'cake.txt',\n",
              " 'bob-marley.txt',\n",
              " 'dickinson.txt',\n",
              " 'nickelback.txt',\n",
              " 'beatles.txt',\n",
              " 'dj-khaled.txt',\n",
              " 'missy-elliott.txt',\n",
              " 'notorious_big.txt',\n",
              " 'kanye-west.txt',\n",
              " 'disney.txt',\n",
              " 'bjork.txt',\n",
              " 'lin-manuel-miranda.txt',\n",
              " 'Kanye_West.txt',\n",
              " 'bruce-springsteen.txt',\n",
              " 'nursery_rhymes.txt',\n",
              " 'drake.txt',\n",
              " 'paul-simon.txt',\n",
              " 'lady-gaga.txt',\n",
              " 'johnny-cash.txt']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Posibles bandas\n",
        "os.listdir(\"./songs_dataset/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "Gb39v3PaZmRH",
        "outputId": "db10c0ad-7fea-4220-edc9-a74a13930ea1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4857f724-343e-4f52-be09-012d44c2eefd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'll undress you, 'cause you're tired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cover you as you desire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When you fall asleep inside my arms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>May not have the fancy things</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But I'll give you everything</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4857f724-343e-4f52-be09-012d44c2eefd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4857f724-343e-4f52-be09-012d44c2eefd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4857f724-343e-4f52-be09-012d44c2eefd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                       0\n",
              "0  I'll undress you, 'cause you're tired\n",
              "1                Cover you as you desire\n",
              "2    When you fall asleep inside my arms\n",
              "3          May not have the fancy things\n",
              "4           But I'll give you everything"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
        "df = pd.read_csv('songs_dataset/lady-gaga.txt', sep='/n', header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riT898QlZnmF",
        "outputId": "85b028df-e006-4efc-b6fb-c9fc3b1dd37d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de documentos: 1846\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDoouHp7Zp6D"
      },
      "source": [
        "### 1 - Ejemplo de Preprocesamiento\n",
        "- Hay que transformar las oraciones en tokens.\n",
        "- Dichas oraciones hay que ajustarlas al tamaño fijo de nuestra sentencia de entrada al modelo.\n",
        "- Hay que separar las palabras objetivos (target) que el modelo debe predecir en cada sentencia armada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer # equivalente a ltokenizer de nltk\n",
        "from keras.preprocessing.text import text_to_word_sequence # equivalente a word_teokenize de nltk\n",
        "from keras.preprocessing.sequence import pad_sequences # se utilizará para padding\n",
        "\n",
        "# largo de la secuencia, incluye seq input + word output\n",
        "train_len = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Zf3O7eK6ZpP8",
        "outputId": "864b50a3-2347-45a0-f727-9c468348300e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'll undress you, 'cause you're tired\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejemplo de como transformar una oración a tokens usando keras\n",
        "text = df.loc[0,0]\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOv67Sj7aeFH",
        "outputId": "7ca7bcaf-030c-403c-e315-3480f2ee42d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"i'll\", 'undress', 'you', \"'cause\", \"you're\", 'tired']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = text_to_word_sequence(text) # entran oraciones -> salen vectores de N posiciones (tokens)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrlyqkoiaymK"
      },
      "source": [
        "1.1 - Transformar las oraciones en secuencias (tokens) de palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XH_L14Wjaowe"
      },
      "outputs": [],
      "source": [
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en secuencias de palabras\n",
        "sentence_tokens = []\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KASzU4CdaxbZ",
        "outputId": "73777bab-fdde-4331-a645-b09a30860b5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[\"i'll\", 'undress', 'you', \"'cause\", \"you're\", 'tired'],\n",
              " ['cover', 'you', 'as', 'you', 'desire']]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Demos un vistazo\n",
        "sentence_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A659lswTbIIB"
      },
      "outputs": [],
      "source": [
        "# Código para hacer el desfazaje de las palabras\n",
        "# según el train_len\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01JEoPPnbgRF",
        "outputId": "f26df797-cebf-4043-85fa-9ae174c3757c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[\"i'll\", 'undress', 'you', \"'cause\"], ['undress', 'you', \"'cause\", \"you're\"]]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Demos un vistazo a nuestros vectores para entrenar el modelo\n",
        "text_sequences "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B0gHnKVa4W_"
      },
      "source": [
        "1.2 - Crear los vectores de palabras (word2vec)\n",
        "\n",
        "Ahora necesitamos pasarlos a números para que lo entienda la red y separar input de output.\n",
        "- El Input seran integers (word2vec)\n",
        "- Mientras que el output será one hot encodeado (labels) del tamaño del vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fkPNvXeQcS0U"
      },
      "outputs": [],
      "source": [
        "tok = Tokenizer() \n",
        "\n",
        "# El tokeinzer \"aprende\" las palabras que se usaran\n",
        "# Se construye (fit) una vez por proyecto, se aplica N veces (tal cual un encoder)\n",
        "tok.fit_on_texts(text_sequences) \n",
        "\n",
        "# Convertimos las palabras a números\n",
        "# entran palabras -> salen números\n",
        "sequences = tok.texts_to_sequences(text_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SIc44IocyQb",
        "outputId": "0b55a426-5a92-44be-b262-928662ad48fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[4, 1, 2, 3], [1, 2, 3, 5]]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ahora sequences tiene los números \"ID\", largo 4\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ro81yCQc1oX",
        "outputId": "1b59f3ea-d3e0-4eac-d440-c260030cefe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de casos (doc) de entrada\n",
        "print(tok.document_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzAWNfroc4u1",
        "outputId": "e07325f0-b52d-43e5-ca30-420d01c54d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de veces que aparece cada palabra\n",
        "print(len(tok.word_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spTBxmFQc6h8",
        "outputId": "ef298e1d-a9fd-46ef-f7dc-ba5eaba226a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'undress': 1, 'you': 2, \"'cause\": 3, \"i'll\": 4, \"you're\": 5}\n"
          ]
        }
      ],
      "source": [
        "# El índice para cada palabra\n",
        "# El sistema las ordena de las más populares a las menos populares\n",
        "print(tok.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUDkjy80c77h",
        "outputId": "52b761da-0287-47d2-925a-7c2d953081c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {\"'cause\": 2, \"i'll\": 1, 'you': 2, 'undress': 2, \"you're\": 1})\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de veces quea aparece cada palabra en cada \"documento\"\n",
        "# (1 documento = 1 caso de entrada)\n",
        "print(tok.word_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohS5Tao1d2KB"
      },
      "source": [
        "### 2 - Preprocesamiento completo\n",
        "Debemos realizar los mismos pasos que en el ejemplo anterior, pero antes de eso debemos transformar ese dataset de filas de oraciones en un texto completo continuo para poder extraer el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Z2-Se2t27r",
        "outputId": "496d9ca4-c055-4765-b796-4b2e60e9ba8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                 I'll undress you, 'cause you're tired\n",
              "1                               Cover you as you desire\n",
              "2                   When you fall asleep inside my arms\n",
              "3                         May not have the fancy things\n",
              "4                          But I'll give you everything\n",
              "5     You could ever want, it's in my arms So baby t...\n",
              "6                        And I will give you everything\n",
              "7                                   So baby tell me yes\n",
              "8                       And I will be all yours tonight\n",
              "9                                   So baby tell me yes\n",
              "10                       And I will give you everything\n",
              "11    I will be right by your side If I can't find t...\n",
              "12                            I'll fix you with my love\n",
              "13                        No matter what you know, I'll\n",
              "14                            I'll fix you with my love\n",
              "15                           And if you say you're okay\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vistazo a las primeras filas\n",
        "df.loc[:15,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "kILsSoxTuHEr",
        "outputId": "42cff338-2329-4e17-d80c-880f7a80c2d6"
      },
      "outputs": [],
      "source": [
        "# Concatenamos todos los rows en un solo valor\n",
        "corpus = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=0)[0]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KlsYd7_uOez",
        "outputId": "3dd89cdf-ab3b-496b-e7b3-68281e762073"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"i'll\",\n",
              " 'undress',\n",
              " 'you',\n",
              " \"'cause\",\n",
              " \"you're\",\n",
              " 'tired',\n",
              " 'cover',\n",
              " 'you',\n",
              " 'as',\n",
              " 'you',\n",
              " 'desire',\n",
              " 'when',\n",
              " 'you',\n",
              " 'fall',\n",
              " 'asleep',\n",
              " 'inside',\n",
              " 'my',\n",
              " 'arms',\n",
              " 'may',\n",
              " 'not']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transformar el corpus a tokens\n",
        "tokens=text_to_word_sequence(corpus)\n",
        "# Vistazo general de los primeros tokens\n",
        "tokens[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlqpZSJOJ1xQ",
        "outputId": "c8f54ded-edc7-4622-cafc-82b0dfcb31ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de tokens en el corpus: 30300\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de tokens en el corpus:\", len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RhQevOynuYk2"
      },
      "outputs": [],
      "source": [
        "# Código para hacer el desfazaje de las palabras\n",
        "# según el train_len\n",
        "text_sequences = []\n",
        "for i in range(train_len, len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU3FuqHSuhzq",
        "outputId": "3f811322-ac31-4b7a-be77-4bb0ce055fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[\"i'll\", 'undress', 'you', \"'cause\"],\n",
              " ['undress', 'you', \"'cause\", \"you're\"],\n",
              " ['you', \"'cause\", \"you're\", 'tired'],\n",
              " [\"'cause\", \"you're\", 'tired', 'cover'],\n",
              " [\"you're\", 'tired', 'cover', 'you'],\n",
              " ['tired', 'cover', 'you', 'as'],\n",
              " ['cover', 'you', 'as', 'you'],\n",
              " ['you', 'as', 'you', 'desire'],\n",
              " ['as', 'you', 'desire', 'when'],\n",
              " ['you', 'desire', 'when', 'you'],\n",
              " ['desire', 'when', 'you', 'fall'],\n",
              " ['when', 'you', 'fall', 'asleep'],\n",
              " ['you', 'fall', 'asleep', 'inside'],\n",
              " ['fall', 'asleep', 'inside', 'my'],\n",
              " ['asleep', 'inside', 'my', 'arms'],\n",
              " ['inside', 'my', 'arms', 'may'],\n",
              " ['my', 'arms', 'may', 'not'],\n",
              " ['arms', 'may', 'not', 'have'],\n",
              " ['may', 'not', 'have', 'the'],\n",
              " ['not', 'have', 'the', 'fancy']]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Demos un vistazo a nuestros vectores para entrenar el modelo\n",
        "text_sequences[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "064N2jtLvHRg",
        "outputId": "8bd366ce-b8e8-4650-e4e2-c225c81876ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[35, 980, 2, 61],\n",
              " [980, 2, 61, 37],\n",
              " [2, 61, 37, 826],\n",
              " [61, 37, 826, 407],\n",
              " [37, 826, 407, 2],\n",
              " [826, 407, 2, 46],\n",
              " [407, 2, 46, 2],\n",
              " [2, 46, 2, 723],\n",
              " [46, 2, 723, 56],\n",
              " [2, 723, 56, 2],\n",
              " [723, 56, 2, 297],\n",
              " [56, 2, 297, 827],\n",
              " [2, 297, 827, 244],\n",
              " [297, 827, 244, 6],\n",
              " [827, 244, 6, 580],\n",
              " [244, 6, 580, 360],\n",
              " [6, 580, 360, 38],\n",
              " [580, 360, 38, 108],\n",
              " [360, 38, 108, 3],\n",
              " [38, 108, 3, 643]]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Proceso de tokenizacion\n",
        "tok = Tokenizer() \n",
        "tok.fit_on_texts(text_sequences) \n",
        "\n",
        "# Convertimos las palabras a números\n",
        "# entran palabras -> salen números\n",
        "sequences = tok.texts_to_sequences(text_sequences)\n",
        "\n",
        "# Damos un vistazo\n",
        "sequences[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwsvmvDKKXSP",
        "outputId": "80f939a1-37b9-493a-dc72-c989ed2e00b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de rows del dataset: 30296\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de rows del dataset:\", len(sequences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMVP4bj0vL2e"
      },
      "source": [
        "### 3 - Input y target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx2xwdz3KloJ",
        "outputId": "3327b219-68a5-4bf1-a795-60078867533d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3, 4],\n",
              "       [5, 6, 7, 8]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Con numpy es muy fácil realizar el slicing de vectores\n",
        "ex = np.array([[1,2,3,4],[5,6,7,8]])\n",
        "ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEod7qghvTVt",
        "outputId": "c589f200-fef6-4130-b33c-39a6ede511ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension: (2, 4)\n",
            "Todos los elementos: [[1 2 3 4]\n",
            " [5 6 7 8]]\n",
            "Todos los elementos menos el último: [[1 2 3]\n",
            " [5 6 7]]\n"
          ]
        }
      ],
      "source": [
        "# Con numpy es muy fácil realizar el slicing de vectores\n",
        "print(\"Dimension:\", ex.shape)\n",
        "print(\"Todos los elementos:\", ex)\n",
        "print(\"Todos los elementos menos el último:\", ex[:, :-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i95xWqtCvp8T",
        "outputId": "3a50862a-efbf-45e6-d00b-198358570bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: [[1 2 3]\n",
            " [5 6 7]]\n",
            "Target: [4 8]\n"
          ]
        }
      ],
      "source": [
        "input = ex[:,:-1] # todos los rows, menos la ultima col\n",
        "target = ex[:, -1] # última col de cada row\n",
        "\n",
        "print(\"Input:\", input)\n",
        "print(\"Target:\", target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1vJTG65v4Qn",
        "outputId": "fc952410-7467-49ca-ef11-13a854339dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30296, 3)\n",
            "(30296,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ 61,  37, 826, ...,   4, 981,  94])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr_sequences = np.array(sequences)\n",
        "x_data = arr_sequences[:,:-1]\n",
        "y_data_int = arr_sequences[:,-1] # aún falta el oneHotEncoder\n",
        "\n",
        "print(x_data.shape)\n",
        "print(y_data_int.shape)\n",
        "y_data_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln6kVWVlwBBs",
        "outputId": "b807cf15-3837-4b68-d0dc-d440f38fe5ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 'i',\n",
              " 2: 'you',\n",
              " 3: 'the',\n",
              " 4: 'a',\n",
              " 5: 'me',\n",
              " 6: 'my',\n",
              " 7: 'to',\n",
              " 8: 'and',\n",
              " 9: 'oh',\n",
              " 10: \"i'm\",\n",
              " 11: 'your',\n",
              " 12: 'that',\n",
              " 13: 'love',\n",
              " 14: 'be',\n",
              " 15: 'in',\n",
              " 16: 'on',\n",
              " 17: 'it',\n",
              " 18: \"don't\",\n",
              " 19: 'want',\n",
              " 20: 'just',\n",
              " 21: 'eh',\n",
              " 22: 'baby',\n",
              " 23: 'with',\n",
              " 24: 'of',\n",
              " 25: 'but',\n",
              " 26: 'we',\n",
              " 27: 'what',\n",
              " 28: 'wanna',\n",
              " 29: 'like',\n",
              " 30: 'do',\n",
              " 31: 'know',\n",
              " 32: 'so',\n",
              " 33: 'is',\n",
              " 34: 'this',\n",
              " 35: \"i'll\",\n",
              " 36: 'can',\n",
              " 37: \"you're\",\n",
              " 38: 'not',\n",
              " 39: \"can't\",\n",
              " 40: 'could',\n",
              " 41: 'p',\n",
              " 42: 'up',\n",
              " 43: 'one',\n",
              " 44: 'no',\n",
              " 45: 'good',\n",
              " 46: 'as',\n",
              " 47: 'got',\n",
              " 48: 'm',\n",
              " 49: 'for',\n",
              " 50: 'if',\n",
              " 51: 'million',\n",
              " 52: \"it's\",\n",
              " 53: 'way',\n",
              " 54: 'reasons',\n",
              " 55: 'all',\n",
              " 56: 'when',\n",
              " 57: 'heart',\n",
              " 58: 'hair',\n",
              " 59: 'dance',\n",
              " 60: 'gonna',\n",
              " 61: \"'cause\",\n",
              " 62: 'out',\n",
              " 63: 'la',\n",
              " 64: 'girl',\n",
              " 65: 'show',\n",
              " 66: 'ah',\n",
              " 67: 'face',\n",
              " 68: 'boys',\n",
              " 69: 'need',\n",
              " 70: 'muh',\n",
              " 71: 'touch',\n",
              " 72: 'yeah',\n",
              " 73: 'he',\n",
              " 74: 'was',\n",
              " 75: 'body',\n",
              " 76: 'come',\n",
              " 77: 'ha',\n",
              " 78: 'give',\n",
              " 79: 'down',\n",
              " 80: 'make',\n",
              " 81: 'tell',\n",
              " 82: 'take',\n",
              " 83: \"i've\",\n",
              " 84: 'were',\n",
              " 85: 'she',\n",
              " 86: 'read',\n",
              " 87: 'see',\n",
              " 88: \"won't\",\n",
              " 89: 'poker',\n",
              " 90: 'say',\n",
              " 91: 'doo',\n",
              " 92: 'night',\n",
              " 93: 'na',\n",
              " 94: 'man',\n",
              " 95: 'bad',\n",
              " 96: 'boy',\n",
              " 97: 'how',\n",
              " 98: 'at',\n",
              " 99: 'am',\n",
              " 100: 'something',\n",
              " 101: 'call',\n",
              " 102: 'feel',\n",
              " 103: 'time',\n",
              " 104: 'get',\n",
              " 105: 'tonight',\n",
              " 106: 'now',\n",
              " 107: 'teeth',\n",
              " 108: 'have',\n",
              " 109: 'let',\n",
              " 110: 'da',\n",
              " 111: \"let's\",\n",
              " 112: 'name',\n",
              " 113: 'go',\n",
              " 114: 'gaga',\n",
              " 115: 'ooh',\n",
              " 116: 'or',\n",
              " 117: 'put',\n",
              " 118: 'are',\n",
              " 119: 'hey',\n",
              " 120: 'game',\n",
              " 121: 'about',\n",
              " 122: 'her',\n",
              " 123: \"there's\",\n",
              " 124: 'stop',\n",
              " 125: 'think',\n",
              " 126: \"she's\",\n",
              " 127: 'edge',\n",
              " 128: 'yo',\n",
              " 129: 'babe',\n",
              " 130: \"'em\",\n",
              " 131: 'him',\n",
              " 132: 'u',\n",
              " 133: 'chorus',\n",
              " 134: 'around',\n",
              " 135: 'ale',\n",
              " 136: 'g',\n",
              " 137: 'hands',\n",
              " 138: 'marry',\n",
              " 139: 'will',\n",
              " 140: 'right',\n",
              " 141: 'enough',\n",
              " 142: 'alejandro',\n",
              " 143: 'cry',\n",
              " 144: 'walk',\n",
              " 145: 'dreams',\n",
              " 146: 'hot',\n",
              " 147: 'juda',\n",
              " 148: 'uh',\n",
              " 149: 'without',\n",
              " 150: 'y',\n",
              " 151: 'there',\n",
              " 152: 'away',\n",
              " 153: 'nothing',\n",
              " 154: 'video',\n",
              " 155: 'eyes',\n",
              " 156: 'through',\n",
              " 157: 'keep',\n",
              " 158: 'more',\n",
              " 159: 'back',\n",
              " 160: 'where',\n",
              " 161: 'die',\n",
              " 162: 'stay',\n",
              " 163: 'monster',\n",
              " 164: 'born',\n",
              " 165: 'thing',\n",
              " 166: 'play',\n",
              " 167: 'cause',\n",
              " 168: 'real',\n",
              " 169: 'artpop',\n",
              " 170: 'had',\n",
              " 171: 'still',\n",
              " 172: 'romance',\n",
              " 173: 'other',\n",
              " 174: 'beat',\n",
              " 175: 'off',\n",
              " 176: 'wish',\n",
              " 177: 'never',\n",
              " 178: 'aura',\n",
              " 179: 'everything',\n",
              " 180: 'free',\n",
              " 181: 'than',\n",
              " 182: 'sex',\n",
              " 183: 'gypsy',\n",
              " 184: 'try',\n",
              " 185: 'long',\n",
              " 186: 'who',\n",
              " 187: 'perfect',\n",
              " 188: 'chick',\n",
              " 189: 'bang',\n",
              " 190: 'our',\n",
              " 191: 'planet',\n",
              " 192: \"who's\",\n",
              " 193: 'fix',\n",
              " 194: 'his',\n",
              " 195: 'myself',\n",
              " 196: 'us',\n",
              " 197: 's',\n",
              " 198: 'cure',\n",
              " 199: 'always',\n",
              " 200: 'giving',\n",
              " 201: \"givin'\",\n",
              " 202: 'head',\n",
              " 203: 'even',\n",
              " 204: \"you'll\",\n",
              " 205: 'fashion',\n",
              " 206: 'life',\n",
              " 207: 'left',\n",
              " 208: 'phone',\n",
              " 209: 'alright',\n",
              " 210: 'from',\n",
              " 211: 'help',\n",
              " 212: 'ate',\n",
              " 213: 'behind',\n",
              " 214: 'find',\n",
              " 215: 'leave',\n",
              " 216: \"we're\",\n",
              " 217: 'guy',\n",
              " 218: 'gotta',\n",
              " 219: 'together',\n",
              " 220: 'applause',\n",
              " 221: 'really',\n",
              " 222: 'illusion',\n",
              " 223: 'paper',\n",
              " 224: 'track',\n",
              " 225: 'turn',\n",
              " 226: \"he's\",\n",
              " 227: 'nobody',\n",
              " 228: 'them',\n",
              " 229: 'dark',\n",
              " 230: 'scheiße',\n",
              " 231: 'gangsta',\n",
              " 232: 'things',\n",
              " 233: 'promise',\n",
              " 234: 'run',\n",
              " 235: 'look',\n",
              " 236: 'makes',\n",
              " 237: 'some',\n",
              " 238: 'before',\n",
              " 239: 'alone',\n",
              " 240: 'here',\n",
              " 241: 'last',\n",
              " 242: 'else',\n",
              " 243: 'under',\n",
              " 244: 'inside',\n",
              " 245: 'forever',\n",
              " 246: 'better',\n",
              " 247: 'been',\n",
              " 248: 'after',\n",
              " 249: 'too',\n",
              " 250: 'watch',\n",
              " 251: 'world',\n",
              " 252: 'then',\n",
              " 253: 'meet',\n",
              " 254: \"goin'\",\n",
              " 255: 'hear',\n",
              " 256: 'until',\n",
              " 257: 'jandro',\n",
              " 258: 'little',\n",
              " 259: 'speak',\n",
              " 260: 'brown',\n",
              " 261: 'clair',\n",
              " 262: 'aus',\n",
              " 263: 'summer',\n",
              " 264: 'yes',\n",
              " 265: 'cut',\n",
              " 266: 'kiss',\n",
              " 267: 'friends',\n",
              " 268: 'said',\n",
              " 269: 'new',\n",
              " 270: 'its',\n",
              " 271: 'speechless',\n",
              " 272: 'feels',\n",
              " 273: 'happy',\n",
              " 274: 'someone',\n",
              " 275: 'greatest',\n",
              " 276: 'wrong',\n",
              " 277: 'would',\n",
              " 278: 'leather',\n",
              " 279: 'mah',\n",
              " 280: 'home',\n",
              " 281: 'live',\n",
              " 282: 'belong',\n",
              " 283: 'those',\n",
              " 284: 'both',\n",
              " 285: 'whoa',\n",
              " 286: 'while',\n",
              " 287: 'lady',\n",
              " 288: 'feeling',\n",
              " 289: 'wonder',\n",
              " 290: 'ma',\n",
              " 291: 'pray',\n",
              " 292: 'believe',\n",
              " 293: 'work',\n",
              " 294: 'talk',\n",
              " 295: 'wear',\n",
              " 296: 'disco',\n",
              " 297: 'fall',\n",
              " 298: 'okay',\n",
              " 299: 'seem',\n",
              " 300: 'hundred',\n",
              " 301: 'mean',\n",
              " 302: 'mine',\n",
              " 303: 'club',\n",
              " 304: 'high',\n",
              " 305: 'place',\n",
              " 306: 'over',\n",
              " 307: 'follow',\n",
              " 308: 'kind',\n",
              " 309: 'fun',\n",
              " 310: 'they',\n",
              " 311: 'control',\n",
              " 312: 'why',\n",
              " 313: 'judas',\n",
              " 314: 'mind',\n",
              " 315: 'damn',\n",
              " 316: 'huh',\n",
              " 317: 'each',\n",
              " 318: 'blow',\n",
              " 319: 'er',\n",
              " 320: 'loves',\n",
              " 321: 'swine',\n",
              " 322: 'handle',\n",
              " 323: 'care',\n",
              " 324: 'bow',\n",
              " 325: 'worst',\n",
              " 326: 'lord',\n",
              " 327: 'worn',\n",
              " 328: 'might',\n",
              " 329: 'hard',\n",
              " 330: 'record',\n",
              " 331: 'only',\n",
              " 332: 'cherry',\n",
              " 333: 'glory',\n",
              " 334: 'e',\n",
              " 335: 'lay',\n",
              " 336: 'own',\n",
              " 337: 'prayer',\n",
              " 338: 'apart',\n",
              " 339: 'venus',\n",
              " 340: 'light',\n",
              " 341: 'top',\n",
              " 342: 'christmas',\n",
              " 343: 'by',\n",
              " 344: 'should',\n",
              " 345: 'crazy',\n",
              " 346: 'mama',\n",
              " 347: 'hold',\n",
              " 348: 'second',\n",
              " 349: \"callin'\",\n",
              " 350: 'telephone',\n",
              " 351: 'again',\n",
              " 352: 'two',\n",
              " 353: 'another',\n",
              " 354: 'hell',\n",
              " 355: 'red',\n",
              " 356: \"you've\",\n",
              " 357: 'strong',\n",
              " 358: 'loud',\n",
              " 359: 'catch',\n",
              " 360: 'may',\n",
              " 361: 'caught',\n",
              " 362: 'sick',\n",
              " 363: \"ain't\",\n",
              " 364: 'party',\n",
              " 365: 'smoke',\n",
              " 366: 'fool',\n",
              " 367: 'an',\n",
              " 368: 'happens',\n",
              " 369: 'verse',\n",
              " 370: 'thought',\n",
              " 371: 'into',\n",
              " 372: 'these',\n",
              " 373: 'boots',\n",
              " 374: 'day',\n",
              " 375: 'living',\n",
              " 376: 'mirror',\n",
              " 377: \"smokin'\",\n",
              " 378: 'full',\n",
              " 379: 'starstruck',\n",
              " 380: 'downtown',\n",
              " 381: 'cured',\n",
              " 382: 'matter',\n",
              " 383: 'heal',\n",
              " 384: 'song',\n",
              " 385: 'rah',\n",
              " 386: 'ro',\n",
              " 387: 'floor',\n",
              " 388: 'lonely',\n",
              " 389: 'sure',\n",
              " 390: 'lights',\n",
              " 391: 'fernando',\n",
              " 392: \"we'll\",\n",
              " 393: 'duh',\n",
              " 394: 'looked',\n",
              " 395: \"'til\",\n",
              " 396: 'nasty',\n",
              " 397: 'heard',\n",
              " 398: 'making',\n",
              " 399: 'act',\n",
              " 400: 'maybe',\n",
              " 401: 'dum',\n",
              " 402: 'ye',\n",
              " 403: 'aha',\n",
              " 404: 'boom',\n",
              " 405: 'tap',\n",
              " 406: 'funk',\n",
              " 407: 'cover',\n",
              " 408: 'ever',\n",
              " 409: 'bitch',\n",
              " 410: 'sorry',\n",
              " 411: 'girls',\n",
              " 412: 'sometimes',\n",
              " 413: 'please',\n",
              " 414: 'cool',\n",
              " 415: 'drinks',\n",
              " 416: 'forgive',\n",
              " 417: 'fine',\n",
              " 418: 'guess',\n",
              " 419: 'bed',\n",
              " 420: '2',\n",
              " 421: 'sexxx',\n",
              " 422: 'wait',\n",
              " 423: 'best',\n",
              " 424: 'diamond',\n",
              " 425: 'dope',\n",
              " 426: \"bleedin'\",\n",
              " 427: \"needin'\",\n",
              " 428: 'every',\n",
              " 429: 'write',\n",
              " 430: 'made',\n",
              " 431: 'god',\n",
              " 432: 'truth',\n",
              " 433: 'religion',\n",
              " 434: 'any',\n",
              " 435: 'anymore',\n",
              " 436: 'reach',\n",
              " 437: \"dancin'\",\n",
              " 438: 'gold',\n",
              " 439: 'shit',\n",
              " 440: 'cigarette',\n",
              " 441: 'shot',\n",
              " 442: 'lost',\n",
              " 443: 'break',\n",
              " 444: 'fame',\n",
              " 445: 'telling',\n",
              " 446: 'ass',\n",
              " 447: \"doin'\",\n",
              " 448: 'forget',\n",
              " 449: \"wasn't\",\n",
              " 450: 'john',\n",
              " 451: \"lookin'\",\n",
              " 452: 'goddess',\n",
              " 453: 'ich',\n",
              " 454: 'schleiban',\n",
              " 455: 'austa',\n",
              " 456: 'es',\n",
              " 457: 'kumpent',\n",
              " 458: 'üske',\n",
              " 459: 'monstère',\n",
              " 460: 'flaugen',\n",
              " 461: 'fräulein',\n",
              " 462: 'uske',\n",
              " 463: 'ceiling',\n",
              " 464: 'sign',\n",
              " 465: 'hurt',\n",
              " 466: 'underneath',\n",
              " 467: 'brooklyn',\n",
              " 468: 'sing',\n",
              " 469: 'hush',\n",
              " 470: \"i'd\",\n",
              " 471: 'young',\n",
              " 472: 'lover',\n",
              " 473: 'drink',\n",
              " 474: 'nights',\n",
              " 475: 'lot',\n",
              " 476: 'buy',\n",
              " 477: 'papa',\n",
              " 478: 'paparazzi',\n",
              " 479: 'en',\n",
              " 480: 'broken',\n",
              " 481: 'fight',\n",
              " 482: \"hangin'\",\n",
              " 483: 'moment',\n",
              " 484: 'hit',\n",
              " 485: 'much',\n",
              " 486: 'holy',\n",
              " 487: 'l',\n",
              " 488: 'pop',\n",
              " 489: 'ride',\n",
              " 490: 'because',\n",
              " 491: 'leader',\n",
              " 492: 'squealer',\n",
              " 493: 'met',\n",
              " 494: 'americano',\n",
              " 495: 'flawless',\n",
              " 496: 'open',\n",
              " 497: 'used',\n",
              " 498: 'harder',\n",
              " 499: 'electric',\n",
              " 500: 'chapel',\n",
              " 501: 'ho',\n",
              " 502: 'side',\n",
              " 503: 'anything',\n",
              " 504: 'hills',\n",
              " 505: 'hand',\n",
              " 506: 'move',\n",
              " 507: 'yourself',\n",
              " 508: 'mi',\n",
              " 509: 'white',\n",
              " 510: 'busy',\n",
              " 511: 'three',\n",
              " 512: 'roberto',\n",
              " 513: \"that's\",\n",
              " 514: 'spin',\n",
              " 515: 'use',\n",
              " 516: 'ga',\n",
              " 517: 'end',\n",
              " 518: 'doing',\n",
              " 519: 'stick',\n",
              " 520: 'wants',\n",
              " 521: 'dont',\n",
              " 522: 'hope',\n",
              " 523: 'princess',\n",
              " 524: 'wayne',\n",
              " 525: 'blue',\n",
              " 526: 'falls',\n",
              " 527: 'music',\n",
              " 528: 'looking',\n",
              " 529: 'slay',\n",
              " 530: 'old',\n",
              " 531: 'pig',\n",
              " 532: 'cold',\n",
              " 533: 'america',\n",
              " 534: 'law',\n",
              " 535: 'sun',\n",
              " 536: 'nein',\n",
              " 537: 'zedd',\n",
              " 538: 'peek',\n",
              " 539: 'lives',\n",
              " 540: 'unpredictable',\n",
              " 541: 'unemotional',\n",
              " 542: 'donatella',\n",
              " 543: 'bite',\n",
              " 544: 'meat',\n",
              " 545: 'fangs',\n",
              " 546: 'pam',\n",
              " 547: 'tree',\n",
              " 548: 'quit',\n",
              " 549: 'highway',\n",
              " 550: 'stuck',\n",
              " 551: 'revenge',\n",
              " 552: 'lipstick',\n",
              " 553: 'kinda',\n",
              " 554: 'nebraska',\n",
              " 555: 'cars',\n",
              " 556: 'choose',\n",
              " 557: 'everybody',\n",
              " 558: 'knows',\n",
              " 559: 'same',\n",
              " 560: 'remember',\n",
              " 561: 'mouth',\n",
              " 562: 'bars',\n",
              " 563: 'cruel',\n",
              " 564: 'future',\n",
              " 565: \"something's\",\n",
              " 566: 'r',\n",
              " 567: 'boyfriend',\n",
              " 568: 'denim',\n",
              " 569: 'american',\n",
              " 570: 'wild',\n",
              " 571: 'seen',\n",
              " 572: 'mess',\n",
              " 573: 'space',\n",
              " 574: 'voice',\n",
              " 575: 'low',\n",
              " 576: 'funny',\n",
              " 577: 'groove',\n",
              " 578: 'flavor',\n",
              " 579: 'sound',\n",
              " 580: 'arms',\n",
              " 581: 'anyway',\n",
              " 582: 'rub',\n",
              " 583: 'favorite',\n",
              " 584: 'dry',\n",
              " 585: 'which',\n",
              " 586: 'parts',\n",
              " 587: 'faith',\n",
              " 588: 'lovers',\n",
              " 589: 'set',\n",
              " 590: 'rejoice',\n",
              " 591: 'did',\n",
              " 592: \"sippin'\",\n",
              " 593: 'bub',\n",
              " 594: 'faster',\n",
              " 595: 'number',\n",
              " 596: 'rock',\n",
              " 597: 'money',\n",
              " 598: 'woman',\n",
              " 599: 'ready',\n",
              " 600: 'lose',\n",
              " 601: 'dad',\n",
              " 602: 'start',\n",
              " 603: 'going',\n",
              " 604: \"tryin'\",\n",
              " 605: 'tomorrow',\n",
              " 606: 'stand',\n",
              " 607: 'friend',\n",
              " 608: 'king',\n",
              " 609: 'plause',\n",
              " 610: 'scream',\n",
              " 611: 'art',\n",
              " 612: 'weekend',\n",
              " 613: 'naked',\n",
              " 614: 'streets',\n",
              " 615: 'burn',\n",
              " 616: 'hairspray',\n",
              " 617: 'school',\n",
              " 618: 'change',\n",
              " 619: 'bare',\n",
              " 620: 'mistaken',\n",
              " 621: 'somewhere',\n",
              " 622: 'ya',\n",
              " 623: 'stars',\n",
              " 624: 'single',\n",
              " 625: 'fare',\n",
              " 626: 'gone',\n",
              " 627: \"body's\",\n",
              " 628: \"pleadin'\",\n",
              " 629: 'breathe',\n",
              " 630: \"sinner's\",\n",
              " 631: 'slam',\n",
              " 632: 'save',\n",
              " 633: 'pain',\n",
              " 634: \"singin'\",\n",
              " 635: 'circles',\n",
              " 636: 'lift',\n",
              " 637: 'beating',\n",
              " 638: \"ev'ry\",\n",
              " 639: 'voodoo',\n",
              " 640: \"that'll\",\n",
              " 641: 'delicious',\n",
              " 642: 'manicured',\n",
              " 643: 'fancy',\n",
              " 644: 'yours',\n",
              " 645: 'close',\n",
              " 646: 'cycle',\n",
              " 647: 'stare',\n",
              " 648: 'stopped',\n",
              " 649: 'breathing',\n",
              " 650: 'completely',\n",
              " 651: 'aware',\n",
              " 652: 'fathom',\n",
              " 653: 'heartbreak',\n",
              " 654: 'glass',\n",
              " 655: 'listen',\n",
              " 656: 'hide',\n",
              " 657: 'queen',\n",
              " 658: 'insecure',\n",
              " 659: 'black',\n",
              " 660: 'today',\n",
              " 661: 'straight',\n",
              " 662: 'check',\n",
              " 663: 'heels',\n",
              " 664: 'first',\n",
              " 665: 'years',\n",
              " 666: 'clothes',\n",
              " 667: 'whole',\n",
              " 668: 'pay',\n",
              " 669: 'jesus',\n",
              " 670: 'chase',\n",
              " 671: \"we'd\",\n",
              " 672: 'famous',\n",
              " 673: 'point',\n",
              " 674: 'fire',\n",
              " 675: 'rush',\n",
              " 676: \"isn't\",\n",
              " 677: 'gun',\n",
              " 678: \"what's\",\n",
              " 679: 'done',\n",
              " 680: 'shawty',\n",
              " 681: 'round',\n",
              " 682: 'half',\n",
              " 683: 'psychotic',\n",
              " 684: 'lies',\n",
              " 685: 'bring',\n",
              " 686: 'pull',\n",
              " 687: '1',\n",
              " 688: 'bridge',\n",
              " 689: 'bust',\n",
              " 690: 'mission',\n",
              " 691: 'street',\n",
              " 692: 'has',\n",
              " 693: 'german',\n",
              " 694: 'their',\n",
              " 695: 'dream',\n",
              " 696: 'ecstasy',\n",
              " 697: 'cowboy',\n",
              " 698: 'girlfriend',\n",
              " 699: 'bikini',\n",
              " 700: 'paint',\n",
              " 701: 'somebody',\n",
              " 702: 'stones',\n",
              " 703: 'mountain',\n",
              " 704: 'sweet',\n",
              " 705: 're',\n",
              " 706: 'marlboro',\n",
              " 707: 'em',\n",
              " 708: 'drop',\n",
              " 709: 'though',\n",
              " 710: 'nice',\n",
              " 711: 'sad',\n",
              " 712: 'goes',\n",
              " 713: \"didn't\",\n",
              " 714: 'air',\n",
              " 715: 'rich',\n",
              " 716: 'ill',\n",
              " 717: 'wont',\n",
              " 718: 'drum',\n",
              " 719: 'champagne',\n",
              " 720: 'figure',\n",
              " 721: 'onto',\n",
              " 722: 'addicted',\n",
              " 723: 'desire',\n",
              " 724: 'lo',\n",
              " 725: 'je',\n",
              " 726: 'h',\n",
              " 727: 'far',\n",
              " 728: 'drag',\n",
              " 729: 'must',\n",
              " 730: 'broke',\n",
              " 731: 'cannot',\n",
              " 732: \"telephonin'\",\n",
              " 733: 'since',\n",
              " 734: 'came',\n",
              " 735: 'leaving',\n",
              " 736: 'sit',\n",
              " 737: 'bar',\n",
              " 738: 'roll',\n",
              " 739: 'c',\n",
              " 740: 'coming',\n",
              " 741: 'biggest',\n",
              " 742: 'fan',\n",
              " 743: 'dancing',\n",
              " 744: 'mexico',\n",
              " 745: 'bother',\n",
              " 746: 'does',\n",
              " 747: 'hypnotic',\n",
              " 748: 'blueprint',\n",
              " 749: 'clean',\n",
              " 750: 'bleed',\n",
              " 751: 'tight',\n",
              " 752: 'line',\n",
              " 753: 'wow',\n",
              " 754: \"we've\",\n",
              " 755: 'death',\n",
              " 756: 'crown',\n",
              " 757: 'dead',\n",
              " 758: 'beyond',\n",
              " 759: 'gets',\n",
              " 760: 'shoes',\n",
              " 761: 'saying',\n",
              " 762: 'cheer',\n",
              " 763: 'thinking',\n",
              " 764: 'trashy',\n",
              " 765: 'pre',\n",
              " 766: 'miss',\n",
              " 767: 'sexy',\n",
              " 768: 'kick',\n",
              " 769: 'road',\n",
              " 770: 'goodbye',\n",
              " 771: 'trying',\n",
              " 772: \"watchin'\",\n",
              " 773: 'falling',\n",
              " 774: 'modern',\n",
              " 775: 'fast',\n",
              " 776: 'big',\n",
              " 777: 'tramp',\n",
              " 778: 'vamp',\n",
              " 779: 'aphrodite',\n",
              " 780: 'alive',\n",
              " 781: 'human',\n",
              " 782: 'squeal',\n",
              " 783: 'disgusting',\n",
              " 784: 'above',\n",
              " 785: 'tops',\n",
              " 786: 'son',\n",
              " 787: 'rain',\n",
              " 788: 'walks',\n",
              " 789: 'bottle',\n",
              " 790: 'wine',\n",
              " 791: 'having',\n",
              " 792: 'clouds',\n",
              " 793: 'higher',\n",
              " 794: 'getting',\n",
              " 795: 'shoot',\n",
              " 796: 'great',\n",
              " 797: 'filter',\n",
              " 798: 'bump',\n",
              " 799: 'forth',\n",
              " 800: 'star',\n",
              " 801: 'wake',\n",
              " 802: 'sexual',\n",
              " 803: 'power',\n",
              " 804: 'cosmic',\n",
              " 805: \"talkin'\",\n",
              " 806: 'press',\n",
              " 807: 'film',\n",
              " 808: 'cameo',\n",
              " 809: \"gon'\",\n",
              " 810: 'ones',\n",
              " 811: 'tried',\n",
              " 812: 'easy',\n",
              " 813: 'cher',\n",
              " 814: 'wings',\n",
              " 815: 'whose',\n",
              " 816: 'monkey',\n",
              " 817: 'papers',\n",
              " 818: 'business',\n",
              " 819: 'interested',\n",
              " 820: 'fakers',\n",
              " 821: 'voo',\n",
              " 822: 'don',\n",
              " 823: 'ra',\n",
              " 824: 'pa',\n",
              " 825: 'falalalalalalala',\n",
              " 826: 'tired',\n",
              " 827: 'asleep',\n",
              " 828: 'feet',\n",
              " 829: 'legs',\n",
              " 830: 'wrote',\n",
              " 831: 'passion',\n",
              " 832: \"doesn't\",\n",
              " 833: \"lovin'\",\n",
              " 834: 'beautiful',\n",
              " 835: 'mistakes',\n",
              " 836: 'regret',\n",
              " 837: 'different',\n",
              " 838: 'called',\n",
              " 839: 'answer',\n",
              " 840: \"takin'\",\n",
              " 841: 'calls',\n",
              " 842: \"couldn't\",\n",
              " 843: 'sang',\n",
              " 844: 'men',\n",
              " 845: 'york',\n",
              " 846: 'jeans',\n",
              " 847: 'means',\n",
              " 848: 'superstar',\n",
              " 849: 'flames',\n",
              " 850: 'reason',\n",
              " 851: 'dangerous',\n",
              " 852: 'raise',\n",
              " 853: 'spades',\n",
              " 854: 'pair',\n",
              " 855: 'russian',\n",
              " 856: 'many',\n",
              " 857: 'electronic',\n",
              " 858: 'slow',\n",
              " 859: 'ow',\n",
              " 860: 'brain',\n",
              " 861: 'sense',\n",
              " 862: 'burns',\n",
              " 863: 'being',\n",
              " 864: 'dirty',\n",
              " 865: 'aah',\n",
              " 866: 'naughty',\n",
              " 867: 'stone',\n",
              " 868: 'color',\n",
              " 869: 'couple',\n",
              " 870: '3',\n",
              " 871: 'loose',\n",
              " 872: 'climb',\n",
              " 873: 'special',\n",
              " 874: 'morning',\n",
              " 875: 'wandering',\n",
              " 876: 'took',\n",
              " 877: 'nowhere',\n",
              " 878: 'asked',\n",
              " 879: 'honey',\n",
              " 880: 'freak',\n",
              " 881: 'swear',\n",
              " 882: 'spirit',\n",
              " 883: 'least',\n",
              " 884: 'city',\n",
              " 885: 'fucked',\n",
              " 886: 'tells',\n",
              " 887: 'instead',\n",
              " 888: 'looks',\n",
              " 889: 'bedroom',\n",
              " 890: 'galaxy',\n",
              " 891: 'oyster',\n",
              " 892: 'serve',\n",
              " 893: 'mars',\n",
              " 894: 'sweat',\n",
              " 895: 'dress',\n",
              " 896: 'couture',\n",
              " 897: 'word',\n",
              " 898: 'deep',\n",
              " 899: 'skin',\n",
              " 900: 'permission',\n",
              " 901: 'blonde',\n",
              " 902: 'crucify',\n",
              " 903: 'bloody',\n",
              " 904: 'mary',\n",
              " 905: 'jesús',\n",
              " 906: 'cristo',\n",
              " 907: \"ceilin'\",\n",
              " 908: 'hate',\n",
              " 909: \"go'n\",\n",
              " 910: 'five',\n",
              " 911: 'ten',\n",
              " 912: \"c'mon\",\n",
              " 913: 'empty',\n",
              " 914: 'feast',\n",
              " 915: 'rhyme',\n",
              " 916: 'bitches',\n",
              " 917: 'pussy',\n",
              " 918: 'd',\n",
              " 919: 'lines',\n",
              " 920: 'waist',\n",
              " 921: 'fader',\n",
              " 922: 'original',\n",
              " 923: 'trip',\n",
              " 924: 'suppose',\n",
              " 925: 'green',\n",
              " 926: 'taking',\n",
              " 927: 'lets',\n",
              " 928: 'cute',\n",
              " 929: 'well',\n",
              " 930: 'lie',\n",
              " 931: 'wondering',\n",
              " 932: 'ford',\n",
              " 933: 'scared',\n",
              " 934: 'outro',\n",
              " 935: 'former',\n",
              " 936: 'trunk',\n",
              " 937: 'hahahaha',\n",
              " 938: 'size',\n",
              " 939: 'burqa',\n",
              " 940: 'pleasure',\n",
              " 941: 'hustlas',\n",
              " 942: \"walkin'\",\n",
              " 943: \"sayin'\",\n",
              " 944: 'smell',\n",
              " 945: 'repeat',\n",
              " 946: 'hurting',\n",
              " 947: 'bones',\n",
              " 948: \"in'\",\n",
              " 949: 'youre',\n",
              " 950: 'permanently',\n",
              " 951: 'thoughts',\n",
              " 952: 'ways',\n",
              " 953: 'learn',\n",
              " 954: 'laugh',\n",
              " 955: 'till',\n",
              " 956: 'such',\n",
              " 957: 'dita',\n",
              " 958: 'diva',\n",
              " 959: 'rainbow',\n",
              " 960: 'spring',\n",
              " 961: 'season',\n",
              " 962: 'radiate',\n",
              " 963: 'magic',\n",
              " 964: 'misunderstood',\n",
              " 965: 'nah',\n",
              " 966: 'direction',\n",
              " 967: 'tied',\n",
              " 968: 'whatcha',\n",
              " 969: 'salvation',\n",
              " 970: 'steal',\n",
              " 971: 'safe',\n",
              " 972: 'ground',\n",
              " 973: 'awful',\n",
              " 974: \"salon's\",\n",
              " 975: 'manicure',\n",
              " 976: \"care'n\",\n",
              " 977: 'garner',\n",
              " 978: 'serial',\n",
              " 979: 'killer',\n",
              " 980: 'undress',\n",
              " 981: 'goner',\n",
              " 982: 'lullaby',\n",
              " 983: 'ugly',\n",
              " 984: 'sand',\n",
              " 985: 'rear',\n",
              " 986: \"j'veux\",\n",
              " 987: 'ton',\n",
              " 988: 'amour',\n",
              " 989: 'veux',\n",
              " 990: 'capital',\n",
              " 991: 'paws',\n",
              " 992: 'told',\n",
              " 993: 'boudoir',\n",
              " 994: \"nothin'\",\n",
              " 995: 'subway',\n",
              " 996: 'whether',\n",
              " 997: 'beige',\n",
              " 998: 'chola',\n",
              " 999: 'orient',\n",
              " 1000: 'gay',\n",
              " ...}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Palabras del vocabulario\n",
        "tok.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJgVhq1zwEpf",
        "outputId": "57bf1407-3438-45c4-fe56-0b7d582db685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2270"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cantidad de palabras en el vocabulario\n",
        "vocab_size = len(tok.word_counts)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIg2e2WCwXbG",
        "outputId": "4d260ab7-a69c-4629-f6a9-e468c2059838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30296, 2270)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_data_int_offset = y_data_int - 1\n",
        "y_data = to_categorical(y_data_int_offset, num_classes=vocab_size) \n",
        "y_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cOmNZT_weK2",
        "outputId": "bfae3546-2673-4878-8c58-9d4a2f366fa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# largo de la secuencia de entrada\n",
        "input_seq_len = x_data.shape[1] \n",
        "input_seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtwITjgnwlgp",
        "outputId": "7e2cfac5-404f-4956-d4c4-8dd8ea589c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2270"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Largo del vector de salida --> vocab_size\n",
        "output_size = vocab_size\n",
        "output_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzTZRXrrwrvi",
        "outputId": "1aeba9a1-2d9d-4f62-ed2e-2550b1d88248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 3, 5)              11355     \n",
            "                                                                 \n",
            " lstm_41 (LSTM)              (None, 3, 128)            68608     \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 3, 128)            0         \n",
            "                                                                 \n",
            " lstm_42 (LSTM)              (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 2270)              147550    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 367,353\n",
            "Trainable params: 367,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 1628 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_length=input_seq_len))\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128)) # La última capa LSTM no lleva return_sequences\n",
        "model.add(Dense(64, activation='LeakyReLU'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida vuelve al espacio de 1628 palabras posibles\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "model.compile(loss='categorical_crossentropy', optimizer= keras.optimizers.Adam(learning_rate=0.005), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQq1PHDkxDvN",
        "outputId": "8b181f34-d385-475c-c365-a4c34b3002fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "758/758 [==============================] - 11s 10ms/step - loss: 5.9142 - accuracy: 0.0492 - val_loss: 6.4337 - val_accuracy: 0.0411\n",
            "Epoch 2/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 4.8729 - accuracy: 0.1398 - val_loss: 6.3753 - val_accuracy: 0.0888\n",
            "Epoch 3/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 4.0885 - accuracy: 0.2377 - val_loss: 6.5302 - val_accuracy: 0.1129\n",
            "Epoch 4/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 3.4618 - accuracy: 0.3258 - val_loss: 6.7436 - val_accuracy: 0.1262\n",
            "Epoch 5/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 2.9690 - accuracy: 0.3983 - val_loss: 7.3299 - val_accuracy: 0.1368\n",
            "Epoch 6/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 2.5899 - accuracy: 0.4576 - val_loss: 7.5967 - val_accuracy: 0.1587\n",
            "Epoch 7/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 2.2805 - accuracy: 0.5033 - val_loss: 8.0438 - val_accuracy: 0.1561\n",
            "Epoch 8/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 2.0351 - accuracy: 0.5438 - val_loss: 8.4308 - val_accuracy: 0.1612\n",
            "Epoch 9/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 1.8378 - accuracy: 0.5767 - val_loss: 8.4766 - val_accuracy: 0.1667\n",
            "Epoch 10/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 1.6584 - accuracy: 0.6070 - val_loss: 9.0079 - val_accuracy: 0.1743\n",
            "Epoch 11/50\n",
            "758/758 [==============================] - 7s 10ms/step - loss: 1.5180 - accuracy: 0.6345 - val_loss: 8.9100 - val_accuracy: 0.1736\n",
            "Epoch 12/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 1.4033 - accuracy: 0.6537 - val_loss: 9.3537 - val_accuracy: 0.1789\n",
            "Epoch 13/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 1.3106 - accuracy: 0.6722 - val_loss: 9.6815 - val_accuracy: 0.1794\n",
            "Epoch 14/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 1.2141 - accuracy: 0.6911 - val_loss: 9.7820 - val_accuracy: 0.1795\n",
            "Epoch 15/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 1.1410 - accuracy: 0.7071 - val_loss: 10.1597 - val_accuracy: 0.1785\n",
            "Epoch 16/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 1.0809 - accuracy: 0.7171 - val_loss: 10.2340 - val_accuracy: 0.1858\n",
            "Epoch 17/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 1.0289 - accuracy: 0.7259 - val_loss: 10.5559 - val_accuracy: 0.1757\n",
            "Epoch 18/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.9804 - accuracy: 0.7374 - val_loss: 10.7154 - val_accuracy: 0.1851\n",
            "Epoch 19/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.9461 - accuracy: 0.7468 - val_loss: 11.0812 - val_accuracy: 0.1883\n",
            "Epoch 20/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.9007 - accuracy: 0.7573 - val_loss: 11.1151 - val_accuracy: 0.1853\n",
            "Epoch 21/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.8671 - accuracy: 0.7650 - val_loss: 11.1218 - val_accuracy: 0.1860\n",
            "Epoch 22/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.8344 - accuracy: 0.7702 - val_loss: 11.6842 - val_accuracy: 0.1827\n",
            "Epoch 23/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.8145 - accuracy: 0.7759 - val_loss: 11.4805 - val_accuracy: 0.1880\n",
            "Epoch 24/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.7825 - accuracy: 0.7844 - val_loss: 11.8081 - val_accuracy: 0.1898\n",
            "Epoch 25/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.7575 - accuracy: 0.7871 - val_loss: 11.6458 - val_accuracy: 0.1906\n",
            "Epoch 26/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.7470 - accuracy: 0.7912 - val_loss: 12.1470 - val_accuracy: 0.1911\n",
            "Epoch 27/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.7227 - accuracy: 0.7973 - val_loss: 12.1577 - val_accuracy: 0.1913\n",
            "Epoch 28/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.7119 - accuracy: 0.7974 - val_loss: 12.4427 - val_accuracy: 0.1983\n",
            "Epoch 29/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.7068 - accuracy: 0.8040 - val_loss: 12.1058 - val_accuracy: 0.1955\n",
            "Epoch 30/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.6856 - accuracy: 0.8044 - val_loss: 12.3783 - val_accuracy: 0.1932\n",
            "Epoch 31/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.6635 - accuracy: 0.8126 - val_loss: 12.3636 - val_accuracy: 0.1916\n",
            "Epoch 32/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.6578 - accuracy: 0.8126 - val_loss: 12.4398 - val_accuracy: 0.1950\n",
            "Epoch 33/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.6554 - accuracy: 0.8135 - val_loss: 12.1691 - val_accuracy: 0.1964\n",
            "Epoch 34/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.6339 - accuracy: 0.8191 - val_loss: 12.4228 - val_accuracy: 0.1954\n",
            "Epoch 35/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.6295 - accuracy: 0.8180 - val_loss: 12.5535 - val_accuracy: 0.1932\n",
            "Epoch 36/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.6248 - accuracy: 0.8192 - val_loss: 12.7528 - val_accuracy: 0.1919\n",
            "Epoch 37/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.6154 - accuracy: 0.8233 - val_loss: 12.7058 - val_accuracy: 0.1993\n",
            "Epoch 38/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.6035 - accuracy: 0.8273 - val_loss: 12.4315 - val_accuracy: 0.2021\n",
            "Epoch 39/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.5916 - accuracy: 0.8278 - val_loss: 13.0149 - val_accuracy: 0.1924\n",
            "Epoch 40/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.5938 - accuracy: 0.8273 - val_loss: 12.7111 - val_accuracy: 0.1979\n",
            "Epoch 41/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.5800 - accuracy: 0.8310 - val_loss: 12.5758 - val_accuracy: 0.1993\n",
            "Epoch 42/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.5773 - accuracy: 0.8327 - val_loss: 13.1061 - val_accuracy: 0.1916\n",
            "Epoch 43/50\n",
            "758/758 [==============================] - 6s 8ms/step - loss: 0.5604 - accuracy: 0.8349 - val_loss: 13.0246 - val_accuracy: 0.1972\n",
            "Epoch 44/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.5627 - accuracy: 0.8353 - val_loss: 12.9589 - val_accuracy: 0.2005\n",
            "Epoch 45/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.5722 - accuracy: 0.8349 - val_loss: 12.9414 - val_accuracy: 0.1957\n",
            "Epoch 46/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.5576 - accuracy: 0.8356 - val_loss: 12.6452 - val_accuracy: 0.2002\n",
            "Epoch 47/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.5476 - accuracy: 0.8409 - val_loss: 13.2184 - val_accuracy: 0.1972\n",
            "Epoch 48/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.5474 - accuracy: 0.8392 - val_loss: 13.0946 - val_accuracy: 0.1949\n",
            "Epoch 49/50\n",
            "758/758 [==============================] - 6s 9ms/step - loss: 0.5379 - accuracy: 0.8402 - val_loss: 12.9061 - val_accuracy: 0.1960\n",
            "Epoch 50/50\n",
            "758/758 [==============================] - 7s 9ms/step - loss: 0.5418 - accuracy: 0.8377 - val_loss: 12.5782 - val_accuracy: 0.1960\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(x_data, y_data, epochs=50, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "q_orBXOrCsNn",
        "outputId": "cfd33992-f1ad-41cd-ea35-4c07e1fe1a16"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "### 5 - Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy_AXWQWzeeE"
      },
      "outputs": [],
      "source": [
        "# Keras pad_sequences\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
        "# Si la secuencia de entrada supera al input_seq_len (3) se trunca\n",
        "# Si la secuencia es más corta se agregna ceros al comienzo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "# Se utilizará gradio para ensayar el modelo\n",
        "# Herramienta poderosa para crear interfaces rápidas para ensayar modelos\n",
        "# https://gradio.app/\n",
        "import sys\n",
        "!{sys.executable} -m pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "HNyBykvhzs7-",
        "outputId": "096bab8b-c3ab-44ff-db84-b236804679c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://36038.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://36038.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f151403ea10>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://36038.gradio.app')"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = tok.texts_to_sequences([human_text])[0]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=3, padding='pre')\n",
        "    \n",
        "    # Predicción softmax\n",
        "    y_hat = model.predict(encoded).argmax(axis=-1)\n",
        "\n",
        "    # Debemos buscar en el vocabulario la palabra\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    for word, index in tok.word_index.items():\n",
        "        if index == y_hat:\n",
        "            out_word = word\n",
        "            break\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + ' ' + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\",\n",
        "    layout=\"vertical\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### 6 - Generación de secuencias nuevas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, tokenizer, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            tokenizer (keras tokenizer): tonenizer utilizado en el preprocesamiento\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de palabras a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = tokenizer.texts_to_sequences([output_text])[0]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\t\t\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = model.predict(encoded).argmax(axis=-1)\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        # Debemos buscar en el vocabulario la palabra\n",
        "        # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == y_hat:\n",
        "                out_word = word\n",
        "                break\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += ' ' + out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JoFqRC5pxzqS",
        "outputId": "1b21e694-f8d0-4d10-c35c-7e0fcff70f5a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is your own baby'"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='this is your'\n",
        "\n",
        "generate_seq(model, tok, input_text, max_length=3, n_words=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2SHmXbgxQH9"
      },
      "source": [
        "### 7 - Conclusiones\n",
        "En este caso se entreno le modelo con el dataset de las canciones de lady gaga.\n",
        "Como en el ejercicio visto en clase, el modelo no presenta una buena performance en la etapa de entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "4d - predicción_palabra.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 ('uba-env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "ef73d9334d5ce8cdc323e58bc2c037d76376afdd3fe87998db26b15bfda9212b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
