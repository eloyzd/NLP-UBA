{"cells":[{"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Word2vect\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np\n","from operator import itemgetter"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["['que', 'dia', 'es', 'hoy']\n","['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","['martes', 'muchas', 'gracias']\n","{'de', 'dia', 'que', 'martes', 'muchas', 'es', 'el', 'hoy', 'gracias'}\n"]}],"source":["d1 = corpus[0]\n","td1 = d1.split(' ')\n","d2 = corpus[1]\n","td2 = d2.split(' ')\n","d3 = corpus[2]\n","td3 = d3.split(' ')\n","print(td1)\n","print(td2)\n","print(td3)\n","bow = td1 + td2 + td3\n","\n","vocabulary = set(bow)\n","print(vocabulary)"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.        0.2003419]\n"," [2.        0.       ]]\n"]}],"source":["class word2vect():\n","    def __init__(self, corpus):\n","        self.corpus = corpus\n","        self.make_vocab()\n","\n","    def make_vocab(self):\n","        self.docs_qty = len(self.corpus)\n","        bow = []\n","        for doc in corpus:\n","            bow += doc.split(' ')\n","        self.vocab = set(bow)\n","        self.vocab_size = len(self.vocab)\n","        self.word2idx = {}\n","        for i,word in enumerate(self.vocab):\n","            self.word2idx[word] = i\n","\n","    def doc2onehot(self,docs_list):\n","        output = np.zeros(shape=(len(docs_list),self.vocab_size))\n","        for i,doc in enumerate(docs_list):\n","            doc_terms = doc.split(' ')\n","            for term in doc_terms:\n","                if term in vocabulary:\n","                    output[i][self.word2idx[term]] = 1\n","                else:\n","                    pass #se ignoran las palabras que no pertenecen al vocabulario\n","        return output\n","\n","    def doc2frec(self,docs_list):\n","        output = np.zeros(shape=(len(docs_list),self.vocab_size))\n","        for i,doc in enumerate(docs_list):\n","            doc_terms = doc.split(' ')\n","            for term in doc_terms:\n","                if term in vocabulary:\n","                    output[i][self.word2idx[term]] += 1\n","                else:\n","                    pass #se ignoran las palabras que no pertenecen al vocabulario\n","        return output\n","\n","    def tf(self,corpus_doc_idx = None, custom_doc = None):\n","        \n","        if (corpus_doc_idx == None) and (custom_doc == None):\n","            docs = self.corpus\n","        else:\n","            if custom_doc != None:\n","                docs = np.array(custom_doc)\n","            else:\n","                docs = np.array([self.corpus[corpus_doc_idx]])\n","\n","        return self.doc2frec(docs)\n","\n","\n","    def idf(self):\n","        return np.log(self.docs_qty/np.sum(self.doc2onehot(self.corpus),axis = 0))\n","\n","    def tfidf(self,corpus_doc_idx = None, custom_doc = None):\n","         return self.tf(corpus_doc_idx = corpus_doc_idx,custom_doc = custom_doc)*self.idf()\n","\n","    def cos_sort(self, corpus_doc_idx):\n","        simil = []\n","        doc = np.array([self.corpus[corpus_doc_idx]])\n","\n","        for idx, d in enumerate(self.corpus):\n","            simil.append(cosine_similarity(self.tfidf(custom_doc = [d])[0], self.tfidf(custom_doc = doc)[0]))\n","\n","        zipped = np.array(list(zip(simil,list(range(len(simil))))))\n","        sort = sorted(zipped,key=itemgetter(0) )\n","        return np.flip(sort)[1:]\n","    \n","\n","w2v = word2vect(corpus)\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0., 1., 1., 0., 0., 1., 0., 1., 0.],\n","       [1., 1., 0., 1., 0., 1., 1., 1., 0.],\n","       [0., 0., 0., 1., 1., 0., 0., 0., 1.]])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["w2v.doc2onehot(corpus)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"data":{"text/plain":["array([[0., 1., 1., 0., 0., 1., 0., 1., 0.],\n","       [1., 1., 0., 2., 0., 1., 1., 1., 0.],\n","       [0., 0., 0., 1., 1., 0., 0., 0., 1.]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["w2v.doc2frec(corpus)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"data":{"text/plain":["array([[0.        , 0.40546511, 1.09861229, 0.        , 0.        ,\n","        0.40546511, 0.        , 0.40546511, 0.        ]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["w2v.tfidf(0)"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.        0.2003419]\n"," [2.        0.       ]]\n"]}],"source":["print(w2v.cos_sort(0))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"0617616a7a81fc39239c474084aa2e18f136a4b71630d63cc2b686b9edacd136"}}},"nbformat":4,"nbformat_minor":0}
